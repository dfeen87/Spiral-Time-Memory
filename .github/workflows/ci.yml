name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run weekly to catch dependency issues
    - cron: '0 0 * * 0'

jobs:
  test:
    name: Test Python ${{ matrix.python-version }} on ${{ matrix.os }}
    runs-on: ${{ matrix.os }}
    
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        python-version: ['3.9', '3.10', '3.11', '3.12']
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov pytest-xdist
    
    - name: Run tests with coverage
      run: |
        pytest tests/ -v --cov=theory --cov=analysis --cov=simulations --cov-report=xml --cov-report=term-missing -n auto
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v4
      if: matrix.os == 'ubuntu-latest' && matrix.python-version == '3.11'
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false

  lint:
    name: Lint and Format Check
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install linting tools
      run: |
        python -m pip install --upgrade pip
        pip install black flake8 isort mypy
    
    - name: Check code formatting with Black
      run: |
        black --check --diff theory/ analysis/ simulations/ experiments/
    
    - name: Check import sorting with isort
      run: |
        isort --check-only --diff theory/ analysis/ simulations/ experiments/
    
    - name: Lint with flake8
      run: |
        # Stop build if there are Python syntax errors or undefined names
        flake8 theory/ analysis/ simulations/ experiments/ --count --select=E9,F63,F7,F82 --show-source --statistics
        # Exit-zero treats all errors as warnings
        flake8 theory/ analysis/ simulations/ experiments/ --count --exit-zero --max-complexity=10 --max-line-length=100 --statistics
    
    - name: Type check with mypy
      run: |
        mypy theory/ analysis/ --ignore-missing-imports --no-strict-optional
      continue-on-error: true  # Type hints are aspirational

  notebooks:
    name: Test Jupyter Notebooks
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install nbconvert nbformat jupyter
    
    - name: Execute notebooks
      run: |
        for notebook in examples/*.ipynb; do
          echo "Testing $notebook"
          jupyter nbconvert --to notebook --execute --inplace "$notebook" || echo "::warning::Notebook $notebook failed"
        done

  reproducibility:
    name: Reproducibility Check
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run reproducibility tests
      run: |
        # Run same simulation twice with fixed seed
        python -c "
        import numpy as np
        from theory.dynamics import *
        
        np.random.seed(42)
        # Test reproducibility
        cfg = MemoryKernelConfig(kernel_type='exponential', tau_mem=1.0)
        K1 = memory_kernel(np.array([0, 1, 2]), cfg)
        
        np.random.seed(42)
        K2 = memory_kernel(np.array([0, 1, 2]), cfg)
        
        assert np.allclose(K1, K2), 'Reproducibility check failed'
        print('âœ“ Reproducibility verified')
        "

  dependencies:
    name: Check Dependency Versions
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
    
    - name: Check for outdated packages
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip list --outdated
      continue-on-error: true
    
    - name: Security check with pip-audit
      run: |
        pip install pip-audit
        pip-audit --desc
      continue-on-error: true

  build-docs:
    name: Build Documentation
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install sphinx sphinx-rtd-theme nbsphinx
    
    - name: Build documentation
      run: |
        # Placeholder for when docs/ exists
        # cd docs && make html
        echo "Documentation build placeholder"
      continue-on-error: true

  publish-test-results:
    name: Publish Test Results
    needs: test
    runs-on: ubuntu-latest
    if: always()
    
    steps:
    - name: Download test results
      uses: actions/download-artifact@v4
      with:
        name: test-results
      continue-on-error: true
    
    - name: Publish test report
      uses: dorny/test-reporter@v1
      if: always()
      with:
        name: Test Results
        path: 'pytest-results.xml'
        reporter: java-junit
      continue-on-error: true
